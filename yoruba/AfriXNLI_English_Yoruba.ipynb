{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM8EdFV1wGRjFPBrWd+xN36"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ysxMC4000uC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "HR7SU6ftwpWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y git-lfs\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/datasets/masakhane/afrixnli /content/masakhane/afrixnli"
      ],
      "metadata": {
        "id": "WS0zfACRZEr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"./masakhane/afrixnli/data/eng/dev.tsv\"\n",
        "test_path  = \"./masakhane/afrixnli/data/eng/test.tsv\"\n",
        "\n",
        "# Load data set\n",
        "train_df = pd.read_csv(train_path, sep=\"\\t\", header=0)\n",
        "test_df  = pd.read_csv(test_path,  sep=\"\\t\", header=0)\n",
        "\n",
        "print(f\"Train DataFrame shape: {train_df.shape}\")\n",
        "print(f\"Test  DataFrame shape: {test_df.shape}\")"
      ],
      "metadata": {
        "id": "21fVzPtcqnJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "HvIVEYlAqw0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "NCdMXkr4qxMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [HelpMumHQ/AI-translator-eng-to-9ja](https://huggingface.co/HelpMumHQ/AI-translator-eng-to-9ja)"
      ],
      "metadata": {
        "id": "y4yk1l59riAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME_M2M100 = \"HelpMumHQ/AI-translator-eng-to-9ja\"\n",
        "\n",
        "# Load tokenizer & model\n",
        "translator_tokenizer_m2m100 = M2M100Tokenizer.from_pretrained(MODEL_NAME_M2M100)\n",
        "translator_model_m2m100 = M2M100ForConditionalGeneration.from_pretrained(MODEL_NAME_M2M100)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "translator_model_m2m100.to(device)"
      ],
      "metadata": {
        "id": "nZWKLJz4T9WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_texts_m2m100(\n",
        "    texts,\n",
        "    src_lang=\"en\",\n",
        "    tgt_lang=\"yo\",\n",
        "    batch_size=16,\n",
        "    max_length=128,\n",
        "    num_beams=4\n",
        "):\n",
        "    \"\"\"\n",
        "    Translate `texts` (list of strings) from `src_lang` to `tgt_lang`\n",
        "    using the globally-loaded M2M-100 model.\n",
        "    Returns a list[str] of the same length.\n",
        "    \"\"\"\n",
        "    tok = translator_tokenizer_m2m100\n",
        "    mdl = translator_model_m2m100\n",
        "    tok.src_lang = src_lang\n",
        "    decoded_all = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=f\"M2M100 {src_lang}→{tgt_lang}\"):\n",
        "        batch = texts[i : i + batch_size]\n",
        "        enc = tok(\n",
        "            batch,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_length\n",
        "        ).to(device)\n",
        "\n",
        "        gen = mdl.generate(\n",
        "            **enc,\n",
        "            forced_bos_token_id=tok.get_lang_id(tgt_lang),\n",
        "            max_length=max_length,\n",
        "            num_beams=num_beams\n",
        "        )\n",
        "        decoded_all.extend(tok.batch_decode(gen, skip_special_tokens=True))\n",
        "\n",
        "    return decoded_all\n"
      ],
      "metadata": {
        "id": "mNrADftxukWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_COLS = [\"premise\", \"hypothesis\"]\n",
        "for col in TEXT_COLS:\n",
        "    for df in (train_df, test_df):\n",
        "        new_col = f\"{col}_yoruba\"\n",
        "        df_type = \"train\" if df is train_df else \"test\"\n",
        "        print(f\"Translating `{col}` → `{new_col}` in {df_type}…\")\n",
        "        df[new_col] = translate_texts_m2m100(\n",
        "            df[col].astype(str).tolist(),\n",
        "            src_lang=\"en\",\n",
        "            tgt_lang=\"yo\",\n",
        "            batch_size=16\n",
        "        )"
      ],
      "metadata": {
        "id": "5ZwVT5eFwInT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train_translated_m2m100.tsv\", sep=\"\\t\", index=False)\n",
        "test_df.to_csv(\"test_translated_m2m100.tsv\",  sep=\"\\t\", index=False)\n",
        "print(\"Files written: train_translated_m2m100.tsv, test_translated_m2m100.tsv\")"
      ],
      "metadata": {
        "id": "MsGEfq_swOuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dfe = pd.read_csv('./train_translated_m2m100.tsv', sep=\"\\t\", header=0)"
      ],
      "metadata": {
        "id": "mro-Q9Qorvtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dfe.head()"
      ],
      "metadata": {
        "id": "DBCQ8LRrxqVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dfe = pd.read_csv('./test_translated_m2m100.tsv', sep=\"\\t\", header=0)"
      ],
      "metadata": {
        "id": "28Vyvcagxsy4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}